{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Terminonlogy\n",
    "\n",
    "- In scalecast, when reading documentation, it is helpful to know the following terms: `_estimators_`, `_can_be_tuned_`, `_cannot_be_tuned_`, `_sklearn_estimators_`, `_metrics_`, `_determine_best_by_`, `_normalizer_`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_estimators_`\n",
    "- these are the the models that forecast and can be set by using `f.set_estimator(...)`\n",
    "- they come from popular machine learning libraries like scikit-learn, keras, statsmodels, and others\n",
    "- add any sklearn estimators to [`Forecaster`](https://scalecast.readthedocs.io/en/latest/Forecaster/Forecaster.html#src.scalecast.Forecaster.Forecaster.add_sklearn_estimator) and [`MVForecaster`](https://scalecast.readthedocs.io/en/latest/Forecaster/MVForecaster.html#src.scalecast.MVForecaster.MVForecaster.add_sklearn_estimator) classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima\n",
      "combo\n",
      "elasticnet\n",
      "gbt\n",
      "hwes\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "lstm\n",
      "mlp\n",
      "mlr\n",
      "prophet\n",
      "rf\n",
      "ridge\n",
      "rnn\n",
      "sgd\n",
      "silverkite\n",
      "svr\n",
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _estimators_\n",
    "print(*_estimators_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_can_be_tuned_`\n",
    "- the following estimators can be tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arima\n",
      "elasticnet\n",
      "gbt\n",
      "hwes\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "mlp\n",
      "mlr\n",
      "prophet\n",
      "rf\n",
      "ridge\n",
      "sgd\n",
      "silverkite\n",
      "svr\n",
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _can_be_tuned_\n",
    "print(*_can_be_tuned_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_cannot_be_tuned_`\n",
    "- the following cannot be tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo\n",
      "rnn\n",
      "lstm\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _cannot_be_tuned_\n",
    "print(*_cannot_be_tuned_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_sklearn_estimators_`\n",
    "- these all come from scikit-learn or use a scikit-learn API and behave similarly (including being easy-to-tune, accepting a `normalizer` argument, and accepting an `Xvars` argument):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnet\n",
      "gbt\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "mlp\n",
      "mlr\n",
      "rf\n",
      "ridge\n",
      "sgd\n",
      "svr\n",
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _sklearn_estimators_\n",
    "print(*_sklearn_estimators_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding sklearn estimators that are not native to scalecast is easy. see: https://scalecast.readthedocs.io/en/latest/Forecaster/Forecaster.html#src.scalecast.Forecaster.Forecaster.add_sklearn_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_metrics_`\n",
    "- these are all the metrics available to use for model validation `f.set_validation_metric(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2\n",
      "rmse\n",
      "mape\n",
      "mae\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _metrics_\n",
    "print(*_metrics_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_determine_best_by_`\n",
    "- these are all the metrics available to use for model comparison and sorting models best-to-worst `f.export(determine_best_by=...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSetRMSE\n",
      "TestSetMAPE\n",
      "TestSetMAE\n",
      "TestSetR2\n",
      "InSampleRMSE\n",
      "InSampleMAPE\n",
      "InSampleMAE\n",
      "InSampleR2\n",
      "ValidationMetricValue\n",
      "LevelTestSetRMSE\n",
      "LevelTestSetMAPE\n",
      "LevelTestSetMAE\n",
      "LevelTestSetR2\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _determine_best_by_\n",
    "print(*_determine_best_by_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_normalizer_`\n",
    "- these are all the options to scale your data when using an sklearn estimator `f.manual_forecast(normalizer=...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax\n",
      "normalize\n",
      "scale\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from scalecast.Forecaster import _normalizer_\n",
    "print(*_normalizer_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_optimizer_funcs_`\n",
    "- these are the functions you can use to optimize models in `MVForecaster` only\n",
    "- this means that if you use the `\"mean\"` option, which is the object's default, when tuning models, it will choose the best one based on which metric had the best average performance on all series\n",
    "- you can add your own functions by calling `add_optimizer_func()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "min\n",
      "max\n"
     ]
    }
   ],
   "source": [
    "from scalecast.MVForecaster import _optimizer_funcs_\n",
    "print(*_optimizer_funcs_,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding optimizer funcs that are not native to scalecast is easy. see: https://scalecast.readthedocs.io/en/latest/Forecaster/MVForecaster.html#src.scalecast.MVForecaster.MVForecaster.add_optimizer_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
