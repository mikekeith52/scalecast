{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c54b8b",
   "metadata": {},
   "source": [
    "# Forecaster and MVForecaster Attributes\n",
    "\n",
    "- You can look up what metrics and estimators are available for you to use by initiating a `Forecaster` or `MVForecaster` instance and checking the object's attributes. This notebook shows how to do that with `Forecaster` only, but the same attributes exist in `MVForecaster`, unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b442bcb-5060-489d-bece-fd077f564c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalecast.Forecaster import Forecaster\n",
    "from scalecast.MVForecaster import MVForecaster\n",
    "\n",
    "f = Forecaster(\n",
    "    y = [1,2,3,4], # required\n",
    "    current_dates = ['2021-01-01','2021-02-01','2021-03-01','2021-04-01'], # required, can be a numbered index if dates not known/needed\n",
    "    future_dates = None, # optional. this accepts an int type that counts the forecast horizon steps. future dates can be generated after the object is initiated.\n",
    "    test_length = 0, # default is 0, but this accepts int or float types to determine the number/fraction of obs to hold out for model testing\n",
    "    cis = False, # default is False, change to True if you want confidence intervals. requires a test set.\n",
    "    metrics = [\n",
    "        'rmse', # default\n",
    "        'mape', # default\n",
    "        'mae', # default\n",
    "        'r2', # default\n",
    "        'smape',\n",
    "        'mse',\n",
    "        'abias',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343236a8",
   "metadata": {},
   "source": [
    "## `Forecaster.estimators`\n",
    "- These are the the models that forecast and can be set by using `f.set_estimator(...)`.\n",
    "- They come from popular machine learning libraries like scikit-learn, keras, statsmodels, and others.\n",
    "- More estimators can be added, assuming they follow a basic sklearn API, by using the `Forecaster.add_sklearn_estimator()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0caf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator(name='catboost', imported_model=<class 'catboost.core.CatBoostRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='elasticnet', imported_model=<class 'sklearn.linear_model._coordinate_descent.ElasticNet'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='gbt', imported_model=<class 'sklearn.ensemble._gb.GradientBoostingRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='knn', imported_model=<class 'sklearn.neighbors._regression.KNeighborsRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='lasso', imported_model=<class 'sklearn.linear_model._coordinate_descent.Lasso'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='mlp', imported_model=<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='mlr', imported_model=<class 'sklearn.linear_model._base.LinearRegression'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='rf', imported_model=<class 'sklearn.ensemble._forest.RandomForestRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='ridge', imported_model=<class 'sklearn.linear_model._ridge.Ridge'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='sgd', imported_model=<class 'sklearn.linear_model._stochastic_gradient.SGDRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='svr', imported_model=<class 'sklearn.svm._classes.SVR'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='xgboost', imported_model=<class 'xgboost.sklearn.XGBRegressor'>, interpreted_model=<class 'scalecast.models.SKLearnUni'>)\n",
      "Estimator(name='arima', imported_model='auto', interpreted_model=<class 'scalecast.models.ARIMA'>)\n",
      "Estimator(name='hwes', imported_model='auto', interpreted_model=<class 'scalecast.models.HWES'>)\n",
      "Estimator(name='prophet', imported_model='auto', interpreted_model=<class 'scalecast.models.Prophet'>)\n",
      "Estimator(name='rnn', imported_model='auto', interpreted_model=<class 'scalecast.models.RNN'>)\n",
      "Estimator(name='lstm', imported_model='auto', interpreted_model=<class 'scalecast.models.LSTM'>)\n",
      "Estimator(name='naive', imported_model='auto', interpreted_model=<class 'scalecast.models.Naive'>)\n",
      "Estimator(name='tbats', imported_model='auto', interpreted_model=<class 'scalecast.models.TBATS'>)\n",
      "Estimator(name='theta', imported_model='auto', interpreted_model=<class 'scalecast.models.Theta'>)\n",
      "Estimator(name='combo', imported_model='auto', interpreted_model=<class 'scalecast.models.Combo'>)\n"
     ]
    }
   ],
   "source": [
    "print(*f.estimators,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9927d",
   "metadata": {},
   "source": [
    "## `Forecaster.metrics`\n",
    "- These are all the metrics available for use when optimizing models.\n",
    "- All metrics from the [metrics class](https://scalecast.readthedocs.io/en/latest/Forecaster/Util.html#metrics) that accept only two arguments are available and can be passed when initiating the object or later using `Forecaster.set_metrics()`.\n",
    "- Custom metrics and metric functions also accepted, as long as they only take two arguments (array of actuals and array of forecasted values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e6e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetricStore(name='rmse', eval_func=<function Metrics.rmse at 0x12b6e79c0>, lower_is_better=True, min_obs_required=1)\n",
      "MetricStore(name='mape', eval_func=<function Metrics.mape at 0x12af31940>, lower_is_better=True, min_obs_required=1)\n",
      "MetricStore(name='mae', eval_func=<function Metrics.mae at 0x12b6e7a60>, lower_is_better=True, min_obs_required=1)\n",
      "MetricStore(name='r2', eval_func=<function Metrics.r2 at 0x12b6e63e0>, lower_is_better=False, min_obs_required=2)\n",
      "MetricStore(name='smape', eval_func=<function Metrics.smape at 0x12b6e7b00>, lower_is_better=True, min_obs_required=1)\n",
      "MetricStore(name='mse', eval_func=<function Metrics.mse at 0x12b6e7880>, lower_is_better=True, min_obs_required=1)\n",
      "MetricStore(name='abias', eval_func=<function Metrics.smape at 0x12b6e7b00>, lower_is_better=True, min_obs_required=1)\n"
     ]
    }
   ],
   "source": [
    "print(*f.metrics,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0abfa",
   "metadata": {},
   "source": [
    "## `Forecaster.determine_best_by`\n",
    "- These are generated from the metrics in `Forecaster.metrics` and include in-sample, test-set, and validation-set metrics.\n",
    "- Many functions can monitor one of these metrics when applying auto ML methods.\n",
    "- Plots and dataframe exports can be ordered best-to-worst according to any of these.\n",
    "- The difference between 'Level' and non-level only comes into play if `Forecaster.diff()` has been called to difference a series. However, `SeriesTransformer` also differences series, in addition to being able to take more dynamic transformations, making the need to use `Forecaster.diff()` irrelevant. It will soon go away and there will be no distinction between level and non-level metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61da8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationMetricValue\n",
      "TestSetRMSE\n",
      "TestSetMAPE\n",
      "TestSetMAE\n",
      "TestSetR2\n",
      "TestSetSMAPE\n",
      "TestSetMSE\n",
      "TestSetABIAS\n",
      "InSampleRMSE\n",
      "InSampleMAPE\n",
      "InSampleMAE\n",
      "InSampleR2\n",
      "InSampleSMAPE\n",
      "InSampleMSE\n",
      "InSampleABIAS\n"
     ]
    }
   ],
   "source": [
    "print(*f.determine_best_by,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd2a79",
   "metadata": {},
   "source": [
    "## `Forecaster.normalizer`\n",
    "- These are all the options to scale your data when using an sklearn estimator.\n",
    "- All models receive a MinMax scale by default (since it is highly encouraged to always use scaled data for some scikit-learn models), but None is also available as an argument to avoid scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905f8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax\n",
      "normalize\n",
      "scale\n",
      "robust\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(*f.normalizer.keys(),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794b0f4",
   "metadata": {},
   "source": [
    "## `MVForecaster.optimizer_funcs`\n",
    "- These are the functions you can use to optimize models in `MVForecaster` only.\n",
    "- This means that if you use the `\"mean\"` option, which is the object's default, when tuning models, it will choose the best one based on which metric had the best average performance on all series\n",
    "- You can add your own functions by calling `add_optimizer_func()`: see the [docs](https://scalecast.readthedocs.io/en/latest/Forecaster/MVForecaster.html#src.scalecast.MVForecaster.MVForecaster.add_optimizer_func)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65a1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "min\n",
      "max\n"
     ]
    }
   ],
   "source": [
    "mvf = MVForecaster(f, f.copy())\n",
    "print(*mvf.optimizer_funcs.keys(),sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999239e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalecast (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
